{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "    \n",
    "\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_price_data():\n",
    "    tickers_list = ['JPM', 'COST', 'IBM', 'HD', 'ARWR']\n",
    "\n",
    "# Store multiple result sets.\n",
    "    full_price_history = []\n",
    "\n",
    "    for ticker in tickers_list:\n",
    "        price_history = yf.Ticker(ticker).history(period=\"6mo\", interval=\"1d\")\n",
    "\n",
    "        for index, row in price_history.iterrows():\n",
    "            row_data = row.to_dict()\n",
    "            row_data['symbol'] = ticker\n",
    "            full_price_history.append(row_data)\n",
    "\n",
    "    # Dump the data to a CSV file, don't have an index column\n",
    "    price_data = pd.DataFrame(full_price_history)\n",
    "    price_data.to_csv('price_data.csv', index=False)\n",
    "    print(price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('price_data.csv'):\n",
    "    \n",
    "    # Load the data\n",
    "    price_data = pd.read_csv('price_data.csv')\n",
    "\n",
    "else:\n",
    "\n",
    "    # Grab the data and store it.\n",
    "    grab_price_data()\n",
    "\n",
    "    # Load the data\n",
    "    price_data = pd.read_csv('price_data.csv')\n",
    "\n",
    "# Display the head before moving on.\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I Just need the Close\n",
    "price_data = price_data[['symbol','datetime','close','high','low','open','volume']]\n",
    "\n",
    "\n",
    "'''\n",
    "    First, for average investors, the return of an asset is a complete and scaleâ€“free \n",
    "    summary of the investment opportunity. Second, return series are easier to \n",
    "    handle than prices series as they have more attractive statistical properties\n",
    "'''\n",
    "\n",
    "\n",
    "# sort the values by symbol and then date\n",
    "price_data.sort_values(by = ['symbol','datetime'], inplace = True)\n",
    "\n",
    "# calculate the change in price\n",
    "price_data['change_in_price'] = price_data['close'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify rows where the symbol changes\n",
    "mask = price_data['symbol'] != price_data['symbol'].shift(1)\n",
    "\n",
    "# For those rows, let's make the value null\n",
    "price_data['change_in_price'] = np.where(mask == True, np.nan, price_data['change_in_price'])\n",
    "\n",
    "# print the rows that have a null value, should only be 5\n",
    "price_data[price_data.isna().any(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of days out you want to predict\n",
    "days_out = 30\n",
    "\n",
    "# Group by symbol, then apply the rolling function and grab the Min and Max.\n",
    "price_data_smoothed = price_data.groupby(['symbol'])[['close','low','high','open','volume']].transform(lambda x: x.ewm(span = days_out).mean())\n",
    "\n",
    "# Join the smoothed columns with the symbol and datetime column from the old data frame.\n",
    "smoothed_df = pd.concat([price_data[['symbol','datetime']], price_data_smoothed], axis=1, sort=False)\n",
    "\n",
    "smoothed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the number of days out you want to predict\n",
    "days_out = 30\n",
    "\n",
    "# create a new column that will house the flag, and for each group calculate the diff compared to 30 days ago. Then use Numpy to define the sign.\n",
    "smoothed_df['Signal_Flag'] = smoothed_df.groupby('symbol')['close'].transform(lambda x : np.sign(x.diff(days_out)))\n",
    "\n",
    "# print the first 50 rows\n",
    "smoothed_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 14 day RSI\n",
    "n = 14\n",
    "\n",
    "# First make a copy of the data frame twice\n",
    "up_df, down_df = price_data[['symbol','change_in_price']].copy(), price_data[['symbol','change_in_price']].copy()\n",
    "\n",
    "# For up days, if the change is less than 0 set to 0.\n",
    "up_df.loc['change_in_price'] = up_df.loc[(up_df['change_in_price'] < 0), 'change_in_price'] = 0\n",
    "\n",
    "# For down days, if the change is greater than 0 set to 0.\n",
    "down_df.loc['change_in_price'] = down_df.loc[(down_df['change_in_price'] > 0), 'change_in_price'] = 0\n",
    "\n",
    "# We need change in price to be absolute.\n",
    "down_df['change_in_price'] = down_df['change_in_price'].abs()\n",
    "\n",
    "# Calculate the EWMA (Exponential Weighted Moving Average), meaning older values are given less weight compared to newer values.\n",
    "ewma_up = up_df.groupby('symbol')['change_in_price'].transform(lambda x: x.ewm(span = n).mean())\n",
    "ewma_down = down_df.groupby('symbol')['change_in_price'].transform(lambda x: x.ewm(span = n).mean())\n",
    "\n",
    "# Calculate the Relative Strength\n",
    "relative_strength = ewma_up / ewma_down\n",
    "\n",
    "# Calculate the Relative Strength Index\n",
    "relative_strength_index = 100.0 - (100.0 / (1.0 + relative_strength))\n",
    "\n",
    "# Add the info to the data frame.\n",
    "price_data['down_days'] = down_df['change_in_price']\n",
    "price_data['up_days'] = up_df['change_in_price']\n",
    "price_data['RSI'] = relative_strength_index\n",
    "\n",
    "# Display the head.\n",
    "price_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Stochastic Oscillator\n",
    "n = 14\n",
    "\n",
    "# Make a copy of the high and low column.\n",
    "low_14, high_14 = price_data[['symbol','low']].copy(), price_data[['symbol','high']].copy()\n",
    "\n",
    "# Group by symbol, then apply the rolling function and grab the Min and Max.\n",
    "low_14 = low_14.groupby('symbol')['low'].transform(lambda x: x.rolling(window = n).min())\n",
    "high_14 = high_14.groupby('symbol')['high'].transform(lambda x: x.rolling(window = n).max())\n",
    "\n",
    "# Calculate the Stochastic Oscillator.\n",
    "k_percent = 100 * ((price_data['close'] - low_14) / (high_14 - low_14))\n",
    "\n",
    "# Add the info to the data frame.\n",
    "price_data['low_14'] = low_14\n",
    "price_data['high_14'] = high_14\n",
    "price_data['k_percent'] = k_percent\n",
    "\n",
    "# Display the head.\n",
    "price_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Williams %R\n",
    "n = 14\n",
    "\n",
    "# Make a copy of the high and low column.\n",
    "low_14, high_14 = price_data[['symbol','low']].copy(), price_data[['symbol','high']].copy()\n",
    "\n",
    "# Group by symbol, then apply the rolling function and grab the Min and Max.\n",
    "low_14 = low_14.groupby('symbol')['low'].transform(lambda x: x.rolling(window = n).min())\n",
    "high_14 = high_14.groupby('symbol')['high'].transform(lambda x: x.rolling(window = n).max())\n",
    "\n",
    "# Calculate William %R indicator.\n",
    "r_percent = ((high_14 - price_data['close']) / (high_14 - low_14)) * - 100\n",
    "\n",
    "# Add the info to the data frame.\n",
    "price_data['r_percent'] = r_percent\n",
    "\n",
    "# Display the head.\n",
    "price_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MACD\n",
    "ema_26 = price_data.groupby('symbol')['close'].transform(lambda x: x.ewm(span = 26).mean())\n",
    "ema_12 = price_data.groupby('symbol')['close'].transform(lambda x: x.ewm(span = 12).mean())\n",
    "macd = ema_12 - ema_26\n",
    "\n",
    "# Calculate the EMA\n",
    "ema_9_macd = macd.ewm(span = 9).mean()\n",
    "\n",
    "# Store the data in the data frame.\n",
    "price_data['MACD'] = macd\n",
    "price_data['MACD_EMA'] = ema_9_macd\n",
    "\n",
    "# Print the head.\n",
    "price_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the Price Rate of Change\n",
    "n = 9\n",
    "\n",
    "# Calculate the Rate of Change in the Price, and store it in the Data Frame.\n",
    "price_data['Price_Rate_Of_Change'] = price_data.groupby('symbol')['close'].transform(lambda x: x.pct_change(periods = n))\n",
    "\n",
    "# Print the first 30 rows\n",
    "price_data.head(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obv(group):\n",
    "    \n",
    "    # Grab the volume and close column.\n",
    "    volume = group['volume']\n",
    "    change = group['close'].diff()\n",
    "\n",
    "    # intialize the previous OBV\n",
    "    prev_obv = 0\n",
    "    obv_values = []\n",
    "\n",
    "    # calculate the On Balance Volume\n",
    "    for i, j in zip(change, volume):\n",
    "\n",
    "        if i > 0:\n",
    "            current_obv = prev_obv + j\n",
    "        elif i < 0:\n",
    "            current_obv = prev_obv - j\n",
    "        else:\n",
    "            current_obv = prev_obv\n",
    "\n",
    "        # OBV.append(current_OBV)\n",
    "        prev_obv = current_obv\n",
    "        obv_values.append(current_obv)\n",
    "    \n",
    "    # Return a panda series.\n",
    "    return pd.Series(obv_values, index = group.index)\n",
    "        \n",
    "\n",
    "# apply the function to each group\n",
    "obv_groups = price_data.groupby('symbol').apply(obv)\n",
    "\n",
    "# add to the data frame, but drop the old index, before adding it.\n",
    "price_data['On Balance Volume'] = obv_groups.reset_index(level=0, drop=True)\n",
    "\n",
    "# display the data frame.\n",
    "price_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column we wish to predict\n",
    "'''\n",
    "    In this case, let's create an output column that will be 1 if the closing price at time 't' is greater than 't-1' and 0 otherwise.\n",
    "    In other words, if the today's closing price is greater than yesterday's closing price it would be 1.\n",
    "'''\n",
    "\n",
    "# Group by the `Symbol` column, then grab the `Close` column.\n",
    "close_groups = price_data.groupby('symbol')['close']\n",
    "\n",
    "# Apply the lambda function which will return -1.0 for down, 1.0 for up and 0.0 for no change.\n",
    "close_groups = close_groups.transform(lambda x : np.sign(x.diff()))\n",
    "\n",
    "# add the data to the main dataframe.\n",
    "price_data['Prediction'] = close_groups\n",
    "\n",
    "# for simplicity in later sections I'm going to make a change to our prediction column. To keep this as a binary classifier I'll change flat days and consider them up days.\n",
    "price_data.loc[price_data['Prediction'] == 0.0] = 1.0\n",
    "\n",
    "# print the head\n",
    "price_data.head(50)\n",
    "\n",
    "# OPTIONAL CODE: Dump the data frame to a CSV file to examine the data yourself.\n",
    "# price_data.to_csv('final_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to remove all rows that have an NaN value.\n",
    "print('Before NaN Drop we have {} rows and {} columns'.format(price_data.shape[0], price_data.shape[1]))\n",
    "\n",
    "# Any row that has a `NaN` value will be dropped.\n",
    "price_data = price_data.dropna()\n",
    "\n",
    "# Display how much we have left now.\n",
    "print('After NaN Drop we have {} rows and {} columns'.format(price_data.shape[0], price_data.shape[1]))\n",
    "\n",
    "# Print the head.\n",
    "price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our X & Y Columns.\n",
    "X_Cols = price_data[['RSI','k_percent','r_percent','Price_Rate_Of_Change','MACD','On Balance Volume']]\n",
    "Y_Cols = price_data['Prediction']\n",
    "\n",
    "# Split X and y into X_\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Cols, Y_Cols, random_state = 0)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rand_frst_clf = RandomForestClassifier(n_estimators = 100, oob_score = True, criterion = \"gini\", random_state = 0)\n",
    "\n",
    "# Fit the data to the model\n",
    "rand_frst_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rand_frst_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the Accuracy of our Model.\n",
    "print('Correct Prediction (%): ', accuracy_score(y_test, rand_frst_clf.predict(X_test), normalize = True) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the traget names\n",
    "target_names = ['Down Day', 'Up Day']\n",
    "\n",
    "# Build a classifcation report\n",
    "report = classification_report(y_true = y_test, y_pred = y_pred, target_names = target_names, output_dict = True)\n",
    "\n",
    "# Add it to a data frame, transpose it for readability.\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "rf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "true_negatives = rf_matrix[0][0]\n",
    "false_negatives = rf_matrix[1][0]\n",
    "true_positives = rf_matrix[1][1]\n",
    "false_positives = rf_matrix[0][1]\n",
    "\n",
    "accuracy = (true_negatives + true_positives) / (true_negatives + true_positives + false_negatives + false_positives)\n",
    "percision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "specificity = true_negatives / (true_negatives + false_positives)\n",
    "\n",
    "print('Accuracy: {}'.format(float(accuracy)))\n",
    "print('Percision: {}'.format(float(percision)))\n",
    "print('Recall: {}'.format(float(recall)))\n",
    "print('Specificity: {}'.format(float(specificity)))\n",
    "\n",
    "disp = plot_confusion_matrix(rand_frst_clf, X_test, y_test, display_labels = ['Down Day', 'Up Day'], normalize = 'true', cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title('Confusion Matrix - Normalized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance and store in pandas series\n",
    "feature_imp = pd.Series(rand_frst_clf.feature_importances_, index=X_Cols.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the values in a list to plot.\n",
    "x_values = list(range(len(rand_frst_clf.feature_importances_)))\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(feature_imp.values)\n",
    "\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'g-')\n",
    "\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.95, xmin = 0, xmax = len(feature_imp), color = 'r', linestyles = 'dashed')\n",
    "\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, feature_imp.index, rotation = 'vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable')\n",
    "plt.ylabel('Cumulative Importance')\n",
    "plt.title('Random Forest: Feature Importance Graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ROC Curve plot.\n",
    "rfc_disp = plot_roc_curve(rand_frst_clf, X_test, y_test, alpha = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest Out-Of-Bag Error Score: {}'.format(rand_frst_clf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "# Number of trees is not a parameter that should be tuned, but just set large enough usually. There is no risk of overfitting in random forest with growing number of # trees, as they are trained independently from each other. \n",
    "n_estimators = list(range(200, 2000, 200))\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', None, 'log2']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "# Max depth is a parameter that most of the times should be set as high as possible, but possibly better performance can be achieved by setting it lower.\n",
    "max_depth = list(range(10, 110, 10))\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "# Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree. Too high values can also lead to # under-fitting hence depending on the level of underfitting or overfitting, you can tune the values for min_samples_split.\n",
    "min_samples_split = [2, 5, 10, 20, 30, 40]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 7, 12, 14, 16 ,20]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Random Forest Classifier to house optimal parameters\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Specfiy the details of our Randomized Search\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the new Random Classifier trained we can proceed to our regular steps, prediction.\n",
    "rf_random.predict(X_test)\n",
    "\n",
    "\n",
    "'''\n",
    "    ACCURACY\n",
    "'''\n",
    "# Once the predictions have been made, then grab the accuracy score.\n",
    "print('Correct Prediction (%): ', accuracy_score(y_test, rf_random.predict(X_test), normalize = True) * 100.0)\n",
    "\n",
    "\n",
    "'''\n",
    "    CLASSIFICATION REPORT\n",
    "'''\n",
    "# Define the traget names\n",
    "target_names = ['Down Day', 'Up Day']\n",
    "\n",
    "# Build a classifcation report\n",
    "report = classification_report(y_true = y_test, y_pred = y_pred, target_names = target_names, output_dict = True)\n",
    "\n",
    "# Add it to a data frame, transpose it for readability.\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "display(report_df)\n",
    "print('\\n')\n",
    "\n",
    "'''\n",
    "    FEATURE IMPORTANCE\n",
    "'''\n",
    "# Calculate feature importance and store in pandas series\n",
    "feature_imp = pd.Series(rand_frst_clf.feature_importances_, index=X_Cols.columns).sort_values(ascending=False)\n",
    "display(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    ROC CURVE\n",
    "'''\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create an ROC Curve plot.\n",
    "rfc_disp = plot_roc_curve(rand_frst_clf, X_test, y_test, alpha = 0.8, name='ROC Curve', lw=1, ax=ax)\n",
    "\n",
    "# Add our Chance Line\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "# Make it look pretty.\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=\"ROC Curve Random Forest\")\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
